{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMZYKVpg3mPE6JsYPTST74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hashithacd/spark_genre_classification/blob/main/Project_jonre_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyspark\n",
        "# !pip install py4j\n",
        "# !pip show pyspark"
      ],
      "metadata": {
        "id": "5n8SCxHhousU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ttOo9f12oBH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e78d2d1-348f-4d1a-fc9b-56a785358f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, IndexToString\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "I0FTajeIpuGO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spark_session():\n",
        "    # sparkSession = SparkSession.builder.appName('project1').config(\"spark.hadoop.fs.s3a.access.key\", S3_ACCESS_KEY).config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\").config(\"spark.hadoop.fs.s3a.secret.key\", S3_SECRET_KEY).config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\").config('spark.executor.memory', '8g').config('spark.driver.memory', '2g').getOrCreate()\n",
        "    sparkSession = SparkSession.builder.appName('project1').config('spark.executor.memory', '8g').config('spark.driver.memory', '2g').getOrCreate()\n",
        "    return sparkSession\n",
        "\n",
        "sc = get_spark_session() "
      ],
      "metadata": {
        "id": "CYtOrSCHqHtY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "    df = sc.read.csv(\"/content/Mendeley_dataset.csv\", header=True, inferSchema=True)\n",
        "    df = df[[\"artist_name\", \"track_name\", \"release_date\", \"genre\",  \"lyrics\"]]\n",
        "    # df = df[['genre', 'lyrics']]\n",
        "    return df\n",
        "mendeley_df = read_data()"
      ],
      "metadata": {
        "id": "6Szmt3CqqKxv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_pipeline(df):\n",
        "    # Define the stages of the ML pipeline for feature extraction\n",
        "    tokenizer = Tokenizer(inputCol=\"lyrics\", outputCol=\"words\")\n",
        "    stop_words_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered_words\")\n",
        "    hashing_tf = HashingTF(inputCol=stop_words_remover.getOutputCol(), outputCol=\"raw_features\", numFeatures=10000)\n",
        "    idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"features\")\n",
        "\n",
        "    # Index the genre column\n",
        "    genre_indexer = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
        "    genre_indexer_df = genre_indexer.fit(df).transform(df)\n",
        "    # select the distinct genre and genre_index values from the DataFrame\n",
        "    genre_mapper_df = genre_indexer_df.select(col('genre'), col('genre_index')).distinct()\n",
        "\n",
        "    # collect the distinct genre and genre_index values into a Python dictionary\n",
        "    genre_mapper = genre_mapper_df.rdd.collectAsMap()\n",
        "\n",
        "    # # use the mapper to map the indexed genre values to their original genre names\n",
        "    # predicted_df = predicted_df.withColumn('predicted_genre', genre_mapper[col('genre_index')])\n",
        "    \n",
        "    # Define the classification model\n",
        "    # rf = RandomForestClassifier(labelCol=\"genre_index\", featuresCol=\"features\")\n",
        "    # gbt = GBTClassifier(labelCol=\"genre_index\", featuresCol=\"features\", maxIter=10)\n",
        "    nb = NaiveBayes(labelCol=\"genre_index\", featuresCol=\"features\")\n",
        "    # svm = LinearSVC(labelCol=\"genre_index\", featuresCol=\"features\")\n",
        "\n",
        "    # layers = [10000, 50, 7]\n",
        "    # classifier = MultilayerPerceptronClassifier(layers=layers, labelCol=\"genre_index\", featuresCol=\"features\", maxIter=100)\n",
        "\n",
        "\n",
        "    # Define the stages of the ML pipeline for feature extraction and classification\n",
        "    pipeline = Pipeline(stages=[tokenizer, stop_words_remover, hashing_tf, idf, genre_indexer, nb])\n",
        "    \n",
        "    # Split the merged dataset into training and test sets\n",
        "    (training_data, test_data) = df.randomSplit([0.8, 0.2], seed=123)\n",
        "    \n",
        "    # Train the model on the training set\n",
        "    training_model = pipeline.fit(training_data)\n",
        "    return training_model, genre_mapper, test_data\n",
        "\n",
        "\n",
        "traningModel, class_mapper, test_frame = training_pipeline(mendeley_df) \n",
        "\n"
      ],
      "metadata": {
        "id": "2gtG9YRdqnbT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def model_evaluation(model, test_df):\n",
        "    # Evaluate the model's performance on the test set\n",
        "    predictions_df = model.transform(test_df)\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"genre_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(predictions_df)\n",
        "    print(\"Test set accuracy = {:.2f}%\".format(accuracy * 100))\n",
        "    return predictions_df\n",
        "\n",
        "prediction_frame = model_evaluation(traningModel, test_frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl2WsiIQqueo",
        "outputId": "25b69e9d-864a-4f80-be5c-f0286c269db0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy = 33.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkOvNgw8rO4O",
        "outputId": "cbb442be-bc8e-4a58-9ad5-fd4779841570"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pop': 0.0,\n",
              " 'blues': 2.0,\n",
              " 'jazz': 4.0,\n",
              " 'country': 1.0,\n",
              " 'hip hop': 6.0,\n",
              " 'reggae': 5.0,\n",
              " 'rock': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lyrics.txt', 'r') as f:\n",
        "    lyrics = f.read()\n",
        "\n",
        "test_lyrics = pd.DataFrame(columns=['lyrics'])\n",
        "test_lyrics.loc[0] = [lyrics]\n",
        "\n",
        "print(test_lyrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr7e09dLrPXE",
        "outputId": "fb345a71-3439-47c4-b029-3c122d11d53d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              lyrics\n",
            "0  [Intro: Future]\\nIf Young Metro don't trust yo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = sc.createDataFrame(test_lyrics)\n",
        "predictions_df = traningModel.transform(pyspark_df)"
      ],
      "metadata": {
        "id": "oMNmwAU5rSw4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to get the key from the value\n",
        "def get_key(val):\n",
        "    return next(key for key, value in class_mapper.items() if value == val)\n",
        "\n",
        "prediction_value = predictions_df.select(\"prediction\").collect()[0][0]\n",
        "print(prediction_value)\n",
        "get_key(prediction_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4BSuxsfFrcCe",
        "outputId": "b3993a89-530c-4d4a-d25e-b2e61f1adfcf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reggae'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traningModel.write().overwrite().save(\"/content/myModel\")"
      ],
      "metadata": {
        "id": "ItEDDAHfrlLl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "# Load the saved pipeline\n",
        "loaded_pipeline = PipelineModel.load(\"/content/myModel\")\n",
        "\n",
        "# Use the loaded pipeline to make predictions on new data\n",
        "predictions = loaded_pipeline.transform(pyspark_df)"
      ],
      "metadata": {
        "id": "9eP6yJLFsQ_D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FWkosfssc70",
        "outputId": "2d765b9b-ae5f-4521-dbbd-268b48b35556"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[lyrics: string, words: array<string>, filtered_words: array<string>, raw_features: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(val):\n",
        "    return next(key for key, value in class_mapper.items() if value == val)\n",
        "\n",
        "prediction_value = predictions.select(\"prediction\").collect()[0][0]\n",
        "print(prediction_value)\n",
        "get_key(prediction_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M_GwBT3QsgWw",
        "outputId": "8bf0e3ac-7039-4599-f4c7-2ae1bf92da30"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reggae'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}